import os
import sys
import time
from datetime import datetime, timedelta
import subprocess
import json
import logging
import os
from notification_utils import NotificationSender
from barron_news import FinancialNewsCrawler
from kimi_financial_news import KimiFinancialNews  # ä¿®æ”¹ä¸ºKimiè´¢ç»è¦é—»å¯¼å…¥
from local_financial_news import LocalFinancialNews  # æ·»åŠ æœ¬åœ°è´¢ç»è¦é—»å¯¼å…¥
from newsapi_financial_news import NewsAPIFinancialNews  # æ·»åŠ NewsAPIè´¢ç»è¦é—»å¯¼å…¥
from akshare_financial_news import AKShareFinancialNews  # æ·»åŠ AKShareè´¢ç»è¦é—»å¯¼å…¥
from macro_data_getter import MacroDataGetter  # æ·»åŠ å®è§‚ç»æµæ•°æ®è·å–å™¨å¯¼å…¥

class AutoStockAnalyzer:
    """è‡ªåŠ¨è‚¡ç¥¨åˆ†æå™¨ï¼Œç”¨äºå®šæ—¶è¿è¡Œè‚¡ç¥¨åˆ†æä»»åŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–è‡ªåŠ¨åˆ†æå™¨"""
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        self.log_dir = "./logs"
        if not os.path.exists(self.log_dir):
            os.makedirs(self.log_dir)
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()
        
        # é€šçŸ¥å‘é€å™¨
        self.notification_sender = NotificationSender("notification_config.json")
        
        # è´¢ç»æ–°é—»çˆ¬è™«ï¼ˆä¿ç•™ä»¥ä¾¿å…¼å®¹ï¼‰
        self.financial_crawler = FinancialNewsCrawler()
        
        # Kimiè´¢ç»è¦é—»è·å–å™¨ï¼ˆæ›´æ–°ä¸ºKimiï¼‰
        self.kimi_news = KimiFinancialNews("notification_config.json")
        
        # æœ¬åœ°è´¢ç»è¦é—»ç”Ÿæˆå™¨ï¼ˆä½œä¸ºKimi APIçš„æ›¿ä»£æ–¹æ¡ˆï¼‰
        self.local_news = LocalFinancialNews("notification_config.json")
        
        # NewsAPIè´¢ç»è¦é—»è·å–å™¨
        self.newsapi_news = NewsAPIFinancialNews("notification_config.json")
        
        # AKShareè´¢ç»è¦é—»è·å–å™¨ï¼ˆä¸“é—¨ç”¨äºè·å–æ–°æµªè´¢ç»è¦é—»ï¼‰
        self.akshare_news = AKShareFinancialNews("notification_config.json")
        
        # å®è§‚ç»æµæ•°æ®è·å–å™¨
        self.macro_data_getter = MacroDataGetter("notification_config.json")
        
        # è·å–å½“å‰ç›®å½•
        self.current_dir = os.path.dirname(os.path.abspath(__file__))
        
        # é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç°åœ¨ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
        self.config_file = None  # auto_run_config.json å·²è¢«ç§»é™¤
        
        # å®è§‚ç»æµæ•°æ®æ¨é€æ—¶é—´ï¼ˆæ¯å¤©ä¸Šåˆ10:30ï¼‰
        self.macro_data_time = "10:30"
        
        # åŠ è½½é»˜è®¤é…ç½®
        self.config = self._load_config()
        
        # åˆ†æè„šæœ¬è·¯å¾„
        self.analysis_script = os.path.join(self.current_dir, "stock_analysis.py")
        
        # è´¢ç»è¦é—»æ¨é€æ—¶é—´
        self.financial_news_time = "09:00"
    
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        log_file = os.path.join(self.log_dir, f"auto_run_{datetime.now().strftime('%Y%m%d')}.log")
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        
        return logging.getLogger("auto_stock_analyzer")
    
    def _load_config(self):
        """åŠ è½½é…ç½®ï¼ˆç°åœ¨ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œä¸å†è¯»å–é…ç½®æ–‡ä»¶ï¼‰"""
        # ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œauto_run_config.jsonå·²è¢«ç§»é™¤
        default_config = {
            "schedule_time": "09:45",  # é»˜è®¤æ¯å¤©ä¸Šåˆ9:45æ‰§è¡Œ
            "analysis_types": ["industry_flow", "abnormal_volume", "us_stock"],  # é»˜è®¤åˆ†æç±»å‹
            "notification_methods": None,  # é»˜è®¤ä½¿ç”¨notification_config.jsonä¸­çš„æ‰€æœ‰é…ç½®
            "timeout": 300  # é»˜è®¤è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        }
        
        self.logger.info("ä½¿ç”¨å†…ç½®é»˜è®¤é…ç½®")
        return default_config
    
    def run_analysis(self, analysis_types=None):
        """è¿è¡Œè‚¡ç¥¨åˆ†æç¨‹åº
        
        Args:
            analysis_types (list): è¦è¿è¡Œçš„åˆ†æç±»å‹åˆ—è¡¨ï¼Œä¸ºNoneæ—¶ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
        
        Returns:
            str: åˆ†ææŠ¥å‘Šå†…å®¹ï¼Œå¦‚æœè¿è¡Œå¤±è´¥åˆ™è¿”å›None
        """
        self.logger.info("å¼€å§‹è¿è¡Œè‚¡ç¥¨åˆ†æç¨‹åº")
        
        # ç¡®å®šåˆ†æç±»å‹å‚æ•°
        if analysis_types is None:
            analysis_types = self.config.get("analysis_types", [])
        
        # æ„å»ºå‘½ä»¤å‚æ•°
        cmd_args = [sys.executable, self.analysis_script]
        
        # æ ¹æ®åˆ†æç±»å‹æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
        if analysis_types:
            if "industry_flow" in analysis_types:
                cmd_args.append("--industry")
            if "abnormal_volume" in analysis_types:
                cmd_args.append("--volume")
            # ç§»é™¤--uså‚æ•°ï¼Œå› ä¸ºstock_analysis.pyä¸æ”¯æŒè¿™ä¸ªå‚æ•°
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šåˆ†æç±»å‹ï¼Œæ·»åŠ --allå‚æ•°
            cmd_args.append("--all")
        
        self.logger.info(f"è¿è¡Œå‘½ä»¤: {' '.join(cmd_args)}")
        
        try:
            # è¿è¡Œåˆ†æç¨‹åº
            result = subprocess.run(
                cmd_args,
                cwd=self.current_dir,
                capture_output=True,
                text=True,
                timeout=self.config.get("timeout", 300)
            )
            
            # è®°å½•ç¨‹åºè¾“å‡º
            self.logger.info(f"ç¨‹åºè¿”å›ç : {result.returncode}")
            
            # è®°å½•æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡ºï¼Œä½†é¿å…é‡å¤è®°å½•å¤§é‡å†…å®¹
            if result.stdout:
                self.logger.info(f"ç¨‹åºæ ‡å‡†è¾“å‡ºé•¿åº¦: {len(result.stdout)}å­—ç¬¦")
                # å¦‚æœè¾“å‡ºè¾ƒçŸ­ï¼Œè®°å½•å®Œæ•´å†…å®¹
                if len(result.stdout) < 1000:
                    self.logger.info(f"ç¨‹åºæ ‡å‡†è¾“å‡º:\n{result.stdout}")
                else:
                    self.logger.info(f"ç¨‹åºæ ‡å‡†è¾“å‡ºå‰100å­—ç¬¦:\n{result.stdout[:100]}...")
            
            if result.stderr:
                self.logger.warning(f"ç¨‹åºæ ‡å‡†é”™è¯¯è¾“å‡º:\n{result.stderr}")
            
            # æ£€æŸ¥æ˜¯å¦è¿è¡ŒæˆåŠŸ
            if result.returncode == 0:
                self.logger.info("è‚¡ç¥¨åˆ†æç¨‹åºè¿è¡ŒæˆåŠŸ")
                
                # ä»è¾“å‡ºä¸­æå–æ¨é€æ¶ˆæ¯
                push_message = self._extract_push_message(result.stdout)
                return push_message
            else:
                self.logger.error(f"è‚¡ç¥¨åˆ†æç¨‹åºè¿è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                return None
        except subprocess.TimeoutExpired:
            self.logger.error(f"è‚¡ç¥¨åˆ†æç¨‹åºè¿è¡Œè¶…æ—¶ï¼ˆ{self.config.get('timeout', 300)}ç§’ï¼‰")
            return None
        except Exception as e:
            self.logger.error(f"è¿è¡Œè‚¡ç¥¨åˆ†æç¨‹åºæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return None
    
    def _extract_push_message(self, output):
        """ä»ç¨‹åºè¾“å‡ºä¸­æå–æ¨é€æ¶ˆæ¯"""
        # å°è¯•ä»è¾“å‡ºä¸­æå–åˆ†ææŠ¥å‘Š
        # æŸ¥æ‰¾"åˆ†ææŠ¥å‘Š:"åé¢çš„å†…å®¹
        report_start = output.find("\nåˆ†ææŠ¥å‘Š:\n\n")
        if report_start != -1:
            # æå–æŠ¥å‘Šå†…å®¹
            report_content = output[report_start + len("\nåˆ†ææŠ¥å‘Š:\n\n"):]
            # å»é™¤æœ€åçš„"ç¨‹åºæ‰§è¡Œå®Œæ¯•"ä¿¡æ¯
            report_end = report_content.find("\n\n=====")
            if report_end != -1:
                report_content = report_content[:report_end]
            return report_content.strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„æŠ¥å‘Šï¼Œå°è¯•æå–æœ‰ä»·å€¼çš„ä¿¡æ¯
        lines = output.split("\n")
        valuable_lines = []
        
        # æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„è¡Œ
        keywords = ["èµ„é‡‘æµå…¥æœ€å¤š", "èµ„é‡‘æµå‡ºæœ€å¤š", "æˆäº¤é‡æœ€å¤§", "æ¶¨å¹…æœ€å¤§", "è·Œå¹…æœ€å¤§"]
        
        for line in lines:
            for keyword in keywords:
                if keyword in line and line.strip():  # ç¡®ä¿è¡Œä¸ä¸ºç©º
                    valuable_lines.append(line.strip())
                    break
        
        if valuable_lines:
            return "\n".join(valuable_lines)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼Œè¿”å›å®Œæ•´è¾“å‡ºçš„å‰ä¸€éƒ¨åˆ†
        return output[:1000] if len(output) > 1000 else output
    
    def send_notification(self, message):
        """å‘é€é€šçŸ¥"""
        if not message:
            self.logger.error("æ²¡æœ‰å¯å‘é€çš„æ¶ˆæ¯å†…å®¹")
            return False
        
        try:
            title = f"ğŸ“Š è‚¡ç¥¨å¸‚åœºåˆ†ææŠ¥å‘Š ({datetime.now().strftime('%Y-%m-%d')})"
            methods = self.config.get("notification_methods")
            
            # å‘é€é€šçŸ¥
            results = self.notification_sender.send_notification(title, message, methods)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è‡³å°‘ä¸€ç§é€šçŸ¥æ–¹å¼å‘é€æˆåŠŸ
            success = any(result for result in results.values())
            
            if success:
                self.logger.info("é€šçŸ¥å‘é€æˆåŠŸ")
            else:
                self.logger.error("æ‰€æœ‰é€šçŸ¥æ–¹å¼å‡å‘é€å¤±è´¥")
            
            return success
        except Exception as e:
            self.logger.error(f"å‘é€é€šçŸ¥æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return False
            
    def send_macro_data_notification(self):
        """å‘é€å®è§‚ç»æµæ•°æ®é€šçŸ¥"""
        try:
            self.logger.info("å¼€å§‹è·å–å¹¶å‘é€å®è§‚ç»æµæ•°æ®...")
            
            # è·å–ä¸­å›½å®è§‚ç»æµæ•°æ®
            china_macro_data = self.macro_data_getter.get_china_macro_data()
            # è·å–ç¾å›½å®è§‚ç»æµæ•°æ®
            us_macro_data = self.macro_data_getter.get_us_macro_data()
            
            # æ•´ç†é€šçŸ¥å†…å®¹
            content = "ğŸ“Š æ¯æ—¥å®è§‚ç»æµæ•°æ®æ¦‚è§ˆ\n\n"
            
            # æ·»åŠ ä¸­å›½å®è§‚æ•°æ®
            if china_macro_data:
                content += "ğŸ‡¨ğŸ‡³ ä¸­å›½å®è§‚ç»æµæ•°æ®\n"
                for data in china_macro_data:
                    content += f"- {data['æŒ‡æ ‡']}: {data['å€¼']}ï¼ˆ{data['å‘å¸ƒæ—¥æœŸ']}ï¼‰\n"
                content += "\n"
            else:
                content += "ğŸ‡¨ğŸ‡³ ä¸­å›½å®è§‚ç»æµæ•°æ®æš‚æ— æ›´æ–°\n\n"
            
            # æ·»åŠ ç¾å›½å®è§‚æ•°æ®
            if us_macro_data:
                content += "ğŸ‡ºğŸ‡¸ ç¾å›½å®è§‚ç»æµæ•°æ®\n"
                for data in us_macro_data:
                    content += f"- {data['æŒ‡æ ‡']}: {data['å€¼']}ï¼ˆ{data['å‘å¸ƒæ—¥æœŸ']}ï¼‰\n"
            else:
                content += "ğŸ‡ºğŸ‡¸ ç¾å›½å®è§‚ç»æµæ•°æ®æš‚æ— æ›´æ–°\n"
            
            # æ·»åŠ æ•°æ®æ›´æ–°æ—¶é—´
            content += f"\nğŸ”„ æ•°æ®æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            
            # å‘é€é€šçŸ¥
            self.send_notification(content)
            
            # è®°å½•æˆåŠŸå‘é€çš„æ—¥æœŸ
            with open('last_macro_run.txt', 'w', encoding='utf-8') as f:
                f.write(datetime.now().strftime('%Y-%m-%d'))
                
            self.logger.info("å®è§‚ç»æµæ•°æ®é€šçŸ¥å‘é€æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"å‘é€å®è§‚ç»æµæ•°æ®é€šçŸ¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def run_once(self):
        """ä»…è¿è¡Œä¸€æ¬¡åˆ†æ"""
        self.logger.info("===== è‡ªåŠ¨è¿è¡Œè‚¡ç¥¨åˆ†æç¨‹åº - å•æ¬¡æ¨¡å¼ =====")
        
        # è¿è¡Œåˆ†æç¨‹åº
        push_message = self.run_analysis()
        
        if push_message:
            self.logger.info("å‡†å¤‡å‘é€é€šçŸ¥")
            # å‘é€é€šçŸ¥
            self.send_notification(push_message)
        else:
            self.logger.error("æ— æ³•è·å–æ¨é€æ¶ˆæ¯ï¼Œé€šçŸ¥å‘é€å¤±è´¥")
        
        self.logger.info("===== è‡ªåŠ¨è¿è¡Œç»“æŸ =====")
    
    def run_news_only(self):
        """ä»…è¿è¡Œè´¢ç»è¦é—»åŠŸèƒ½ï¼Œå®ç°Kimiâ†’æœ¬åœ°â†’NewsAPIâ†’çˆ¬è™«çš„ä¸‰çº§å›é€€æœºåˆ¶"""
        self.logger.info("===== è¿è¡Œè´¢ç»è¦é—»è·å–åŠŸèƒ½ ======")
        
        today = datetime.now().strftime("%Y-%m-%d")
        self.logger.info(f"å¼€å§‹è·å–æœ€æ–°è´¢ç»è¦é—» ({today})")
        
        # å°è¯•ä½¿ç”¨Kimiå¤§æ¨¡å‹å‘é€è´¢ç»è¦é—»é€šçŸ¥
        try:
            self.logger.info("å°è¯•ä½¿ç”¨Kimiè´¢ç»è¦é—»...")
            success = self.kimi_news.send_news_notification()
            if success:
                self.logger.info("Kimiè´¢ç»è¦é—»æ¨é€æˆåŠŸ")
                return True
            else:
                self.logger.warning("Kimiè´¢ç»è¦é—»æ¨é€å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç”Ÿæˆå™¨...")
        except Exception as e:
            self.logger.error(f"Kimiè´¢ç»è¦é—»æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            self.logger.warning("å°è¯•ä½¿ç”¨æœ¬åœ°ç”Ÿæˆå™¨...")
        
        # å°è¯•ä½¿ç”¨æœ¬åœ°è´¢ç»è¦é—»ç”Ÿæˆå™¨
        try:
            self.logger.info("å°è¯•ä½¿ç”¨æœ¬åœ°ç”Ÿæˆå™¨...")
            success = self.local_news.send_news_notification()
            if success:
                self.logger.info("æœ¬åœ°è´¢ç»è¦é—»æ¨é€æˆåŠŸ")
                return True
            else:
                self.logger.warning("æœ¬åœ°è´¢ç»è¦é—»ç”Ÿæˆå™¨ä¹Ÿå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨NewsAPI...")
        except Exception as e:
            self.logger.error(f"æœ¬åœ°ç”Ÿæˆå™¨æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            self.logger.warning("å°è¯•ä½¿ç”¨NewsAPI...")
        
        # å°è¯•ä½¿ç”¨NewsAPI
        try:
            self.logger.info("å°è¯•ä½¿ç”¨NewsAPI...")
            # æ£€æŸ¥NewsAPIè¿æ¥çŠ¶æ€
            if hasattr(self.newsapi_news, 'check_connection'):
                connection_status = self.newsapi_news.check_connection()
                if not connection_status:
                    self.logger.warning("NewsAPIè¿æ¥æ£€æŸ¥å¤±è´¥ï¼Œå‡†å¤‡å›é€€åˆ°çˆ¬è™«...")
                    # ç›´æ¥å°è¯•çˆ¬è™«ï¼Œä¸è¿›è¡ŒNewsAPIè¯·æ±‚
                    success = self._crawl_and_send_news()
                    if success:
                        return True
                else:
                    self.logger.info("NewsAPIè¿æ¥æ£€æŸ¥æˆåŠŸï¼Œå¼€å§‹è·å–æ–°é—»...")
                    success = self.newsapi_news.send_news_notification()
                    if success:
                        self.logger.info("NewsAPIè´¢ç»è¦é—»æ¨é€æˆåŠŸ")
                        return True
                    else:
                        self.logger.warning("NewsAPIè´¢ç»è¦é—»è·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨çˆ¬è™«...")
            else:
                # å¦‚æœæ²¡æœ‰check_connectionæ–¹æ³•ï¼Œç›´æ¥å°è¯•è·å–æ–°é—»
                success = self.newsapi_news.send_news_notification()
                if success:
                    self.logger.info("NewsAPIè´¢ç»è¦é—»æ¨é€æˆåŠŸ")
                    return True
                else:
                    self.logger.warning("NewsAPIè´¢ç»è¦é—»è·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨çˆ¬è™«...")
        except Exception as e:
            self.logger.error(f"NewsAPIè´¢ç»è¦é—»æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            self.logger.warning("å°è¯•ä½¿ç”¨çˆ¬è™«...")
        
        # å°è¯•ä½¿ç”¨çˆ¬è™«æ–¹å¼
        try:
            success = self._crawl_and_send_news()
            if success:
                return True
        except Exception as e:
            self.logger.error(f"çˆ¬è™«æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        
        # å°è¯•ä½¿ç”¨åŸæœ‰çš„çˆ¬è™«æ–¹å¼ä½œä¸ºæœ€åçš„å…œåº•
        try:
            self.logger.info("å°è¯•ä½¿ç”¨åŸæœ‰çˆ¬è™«æ–¹å¼ä½œä¸ºæœ€åçš„å…œåº•...")
            success = self.financial_crawler.send_news_notification()
            if success:
                self.logger.info("åŸæœ‰çˆ¬è™«æ–¹å¼æ¨é€æˆåŠŸ")
                return True
            else:
                self.logger.warning("åŸæœ‰çˆ¬è™«æ–¹å¼ä¹Ÿå¤±è´¥")
        except Exception as e:
            self.logger.error(f"åŸæœ‰çˆ¬è™«æ–¹å¼æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        
        self.logger.error("æ‰€æœ‰è´¢ç»è¦é—»è·å–æ–¹å¼å‡å¤±è´¥")
        return False
        
    def _crawl_and_send_news(self):
        """ä½¿ç”¨ç®€å•çˆ¬è™«è·å–è´¢ç»è¦é—»å¹¶å‘é€é€šçŸ¥"""
        try:
            self.logger.info("å°è¯•ä½¿ç”¨å¤‡ç”¨çˆ¬è™«è·å–è´¢ç»è¦é—»...")
            news_content = self._crawl_financial_news()
            if news_content:
                self.logger.info("çˆ¬è™«è·å–è´¢ç»è¦é—»æˆåŠŸ")
                # ä½¿ç”¨Kimiçš„é€šçŸ¥æ–¹æ³•å‘é€çˆ¬è™«è·å–çš„æ–°é—»
                title = f"ğŸ“° è´¢ç»è¦é—» ({datetime.now().strftime('%Y-%m-%d')})"
                results = self.notification_sender.send_notification(title, news_content)
                success = any(result for result in results.values())
                if success:
                    self.logger.info("çˆ¬è™«è·å–çš„è´¢ç»è¦é—»æ¨é€æˆåŠŸ")
                else:
                    self.logger.warning("çˆ¬è™«è·å–çš„è´¢ç»è¦é—»æ¨é€å¤±è´¥")
                return success
            else:
                self.logger.warning("çˆ¬è™«æœªè·å–åˆ°ä»»ä½•æ–°é—»")
                return False
        except Exception as e:
            self.logger.error(f"çˆ¬è™«åŠŸèƒ½æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return False
            
    def _crawl_financial_news(self):
        """ç®€å•çš„è´¢ç»è¦é—»çˆ¬è™«å®ç°ï¼Œä½œä¸ºæœ€åçš„å›é€€æœºåˆ¶"""
        try:
            import requests
            from bs4 import BeautifulSoup
            from datetime import datetime
            
            self.logger.info("ä½¿ç”¨ç®€å•çˆ¬è™«è·å–è´¢ç»è¦é—»")
            
            # è¿™é‡Œé€‰æ‹©ä¸€äº›å¯è®¿é—®çš„ä¸­æ–‡è´¢ç»ç½‘ç«™ä½œä¸ºçˆ¬è™«ç›®æ ‡
            # æ³¨æ„ï¼šå®é™…ä½¿ç”¨æ—¶è¯·éµå®ˆç½‘ç«™çš„robots.txtè§„åˆ™
            news_sources = [
                {
                    'name': 'æ–°æµªè´¢ç»',
                    'url': 'https://finance.sina.com.cn/',
                    'selector': '.news-item'
                },
                {
                    'name': 'ä¸œæ–¹è´¢å¯Œç½‘',
                    'url': 'https://finance.eastmoney.com/',
                    'selector': '.newsflash_body li'
                }
            ]
            
            crawled_news = []
            max_articles = 10
            
            for source in news_sources:
                if len(crawled_news) >= max_articles:
                    break
                
                try:
                    self.logger.info(f"çˆ¬å–{source['name']}...")
                    response = requests.get(source['url'], timeout=10)
                    response.encoding = 'utf-8'
                    
                    soup = BeautifulSoup(response.text, 'html.parser')
                    items = soup.select(source['selector'])
                    
                    for i, item in enumerate(items):
                        if len(crawled_news) >= max_articles:
                            break
                        
                        try:
                            # æ ¹æ®ä¸åŒç½‘ç«™çš„ç»“æ„æå–æ ‡é¢˜å’Œé“¾æ¥
                            if source['name'] == 'æ–°æµªè´¢ç»':
                                a_tag = item.select_one('a')
                                if a_tag:
                                    title = a_tag.get_text().strip()
                                    link = a_tag.get('href')
                                    if title and len(title) > 5:
                                        crawled_news.append({
                                            'title': title,
                                            'source': source['name'],
                                            'url': link,
                                            'publishedAt': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                        })
                            elif source['name'] == 'ä¸œæ–¹è´¢å¯Œç½‘':
                                a_tag = item.select_one('a')
                                if a_tag:
                                    title = a_tag.get_text().strip()
                                    link = a_tag.get('href')
                                    if title and len(title) > 5:
                                        crawled_news.append({
                                            'title': title,
                                            'source': source['name'],
                                            'url': link,
                                            'publishedAt': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                        })
                        except Exception as e:
                            self.logger.warning(f"è§£æ{source['name']}æ–°é—»é¡¹æ—¶å‡ºé”™: {str(e)}")
                except Exception as e:
                    self.logger.warning(f"çˆ¬å–{source['name']}æ—¶å‡ºé”™: {str(e)}")
            
            # æ ¼å¼åŒ–çˆ¬å–çš„æ–°é—»
            if crawled_news:
                formatted_news = "ã€çˆ¬è™«è·å–è´¢ç»è¦é—»ã€‘\n\n"
                formatted_news += f"æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                
                for i, news in enumerate(crawled_news, 1):
                    formatted_news += f"{i}. {news['title']}\n"
                    formatted_news += f"   æ¥æº: {news['source']}\n"
                    formatted_news += f"   é“¾æ¥: {news['url']}\n\n"
                
                formatted_news += "\næ³¨æ„ï¼šæœ¬æ–°é—»ç”±çˆ¬è™«è‡ªåŠ¨æŠ“å–ï¼Œå¯èƒ½å­˜åœ¨æ—¶æ•ˆæ€§é—®é¢˜ï¼Œä»…ä¾›å‚è€ƒã€‚"
                return formatted_news
            else:
                self.logger.warning("çˆ¬è™«æœªè·å–åˆ°ä»»ä½•æ–°é—»")
                return None
        except Exception as e:
            self.logger.error(f"çˆ¬è™«åŠŸèƒ½æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return None
    
    def run_scheduled(self):
        """å¯åŠ¨å®šæ—¶ä»»åŠ¡æ¨¡å¼"""
        self.logger.info("===== è‡ªåŠ¨è¿è¡Œè‚¡ç¥¨åˆ†æç¨‹åº - å®šæ—¶æ¨¡å¼ ======")
        self.logger.info(f"æ¯å¤©é¢„å®šæ‰§è¡Œæ—¶é—´: {self.config.get('schedule_time', '09:45')}")
        self.logger.info(f"æ¯å¤©è´¢ç»è¦é—»æ¨é€æ—¶é—´: {self.financial_news_time}")
        self.logger.info(f"æ¯å¤©æ–°æµªè´¢ç»è¦é—»æ¨é€æ—¶é—´: 17:00")
        self.logger.info(f"æ¯å¤©å®è§‚ç»æµæ•°æ®æ¨é€æ—¶é—´: {self.macro_data_time}")
        
        while True:
            try:
                # è·å–å½“å‰æ—¶é—´
                now = datetime.now()
                current_time = now.strftime("%H:%M")
                today = now.strftime("%Y-%m-%d")
                
                # è·å–é¢„å®šæ‰§è¡Œæ—¶é—´
                schedule_time = self.config.get("schedule_time", "09:45")
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾è´¢ç»è¦é—»æ¨é€æ—¶é—´
                if current_time == self.financial_news_time:
                    # æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»æ¨é€è¿‡è´¢ç»è¦é—»
                    financial_last_run_file = os.path.join(self.log_dir, "last_financial_run.txt")
                    
                    if os.path.exists(financial_last_run_file):
                        with open(financial_last_run_file, 'r') as f:
                            financial_last_run_date = f.read().strip()
                    else:
                        financial_last_run_date = ""
                    
                    if financial_last_run_date != today:
                        self.logger.info(f"åˆ°è¾¾è´¢ç»è¦é—»æ¨é€æ—¶é—´: {self.financial_news_time}ï¼Œå¼€å§‹æ¨é€æœ€æ–°è´¢ç»è¦é—»")
                        
                        # ä½¿ç”¨Kimiå¤§æ¨¡å‹å‘é€è´¢ç»è¦é—»é€šçŸ¥ï¼ˆæ›¿æ¢åŸæ¥çš„çˆ¬è™«æ–¹å¼ï¼‰
                        success = self.kimi_news.send_news_notification()
                        
                        # å¦‚æœKimiå¤§æ¨¡å‹å¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°è´¢ç»è¦é—»ç”Ÿæˆå™¨
                        if not success:
                            self.logger.warning("Kimiè´¢ç»è¦é—»æ¨é€å¤±è´¥ï¼Œåˆ‡æ¢åˆ°æœ¬åœ°è´¢ç»è¦é—»ç”Ÿæˆå™¨")
                            success = self.local_news.send_news_notification()
                        
                        # å¦‚æœæœ¬åœ°ç”Ÿæˆå™¨ä¹Ÿå¤±è´¥ï¼Œå†å›é€€åˆ°åŸæœ‰çš„çˆ¬è™«æ–¹å¼
                        if not success:
                            self.logger.warning("æœ¬åœ°è´¢ç»è¦é—»ç”Ÿæˆå™¨ä¹Ÿå¤±è´¥ï¼Œå›é€€åˆ°çˆ¬è™«æ–¹å¼")
                            success = self.financial_crawler.send_news_notification()
                        
                        if success:
                            self.logger.info("è´¢ç»è¦é—»æ¨é€å®Œæˆ")
                            # è®°å½•ä»Šå¤©å·²æ¨é€
                            with open(financial_last_run_file, 'w') as f:
                                f.write(today)
                        else:
                            self.logger.error("è´¢ç»è¦é—»æ¨é€å¤±è´¥")
                    else:
                        self.logger.info(f"ä»Šå¤©({today})å·²ç»æ¨é€è¿‡è´¢ç»è¦é—»ï¼Œè·³è¿‡æœ¬æ¬¡æ¨é€")
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æ–°æµªè´¢ç»è¦é—»æ¨é€æ—¶é—´ï¼ˆæ¯å¤©ä¸‹åˆ5ç‚¹ï¼‰
                if current_time == "17:00":
                    # æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»æ¨é€è¿‡æ–°æµªè´¢ç»è¦é—»
                    sina_last_run_file = os.path.join(self.log_dir, "last_sina_news_run.txt")
                    
                    if os.path.exists(sina_last_run_file):
                        with open(sina_last_run_file, 'r') as f:
                            sina_last_run_date = f.read().strip()
                    else:
                        sina_last_run_date = ""
                    
                    if sina_last_run_date != today:
                        self.logger.info(f"åˆ°è¾¾æ–°æµªè´¢ç»è¦é—»æ¨é€æ—¶é—´: 17:00ï¼Œå¼€å§‹æ¨é€æœ€æ–°æ–°æµªè´¢ç»è¦é—»")
                        
                        # ä½¿ç”¨AKShareè·å–æ–°æµªè´¢ç»è¦é—»
                        try:
                            success = self.akshare_news.send_news_notification()
                            if success:
                                self.logger.info("æ–°æµªè´¢ç»è¦é—»æ¨é€æˆåŠŸ")
                                # è®°å½•ä»Šå¤©å·²æ¨é€
                                with open(sina_last_run_file, 'w') as f:
                                    f.write(today)
                            else:
                                self.logger.error("æ–°æµªè´¢ç»è¦é—»æ¨é€å¤±è´¥")
                        except Exception as e:
                            self.logger.error(f"è·å–æ–°æµªè´¢ç»è¦é—»æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                    else:
                        self.logger.info(f"ä»Šå¤©({today})å·²ç»æ¨é€è¿‡æ–°æµªè´¢ç»è¦é—»ï¼Œè·³è¿‡æœ¬æ¬¡æ¨é€")
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾å®è§‚ç»æµæ•°æ®æ¨é€æ—¶é—´
                if current_time == self.macro_data_time:
                    # æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»æ¨é€è¿‡å®è§‚ç»æµæ•°æ®
                    macro_last_run_file = os.path.join(self.log_dir, "last_macro_run.txt")
                    
                    if os.path.exists(macro_last_run_file):
                        with open(macro_last_run_file, 'r') as f:
                            macro_last_run_date = f.read().strip()
                    else:
                        macro_last_run_date = ""
                    
                    if macro_last_run_date != today:
                        self.logger.info(f"åˆ°è¾¾å®è§‚ç»æµæ•°æ®æ¨é€æ—¶é—´: {self.macro_data_time}ï¼Œå¼€å§‹æ¨é€æœ€æ–°ä¸­ç¾å®è§‚ç»æµæ•°æ®")
                        
                        # è·å–å¹¶å‘é€å®è§‚ç»æµæ•°æ®
                        try:
                            success = self.macro_data_getter.send_macro_data_notification()
                            if success:
                                self.logger.info("å®è§‚ç»æµæ•°æ®æ¨é€æˆåŠŸ")
                                # è®°å½•ä»Šå¤©å·²æ¨é€
                                with open(macro_last_run_file, 'w') as f:
                                    f.write(today)
                            else:
                                self.logger.error("å®è§‚ç»æµæ•°æ®æ¨é€å¤±è´¥")
                        except Exception as e:
                            self.logger.error(f"è·å–å®è§‚ç»æµæ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                    else:
                        self.logger.info(f"ä»Šå¤©({today})å·²ç»æ¨é€è¿‡å®è§‚ç»æµæ•°æ®ï¼Œè·³è¿‡æœ¬æ¬¡æ¨é€")
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾è‚¡ç¥¨åˆ†ææ‰§è¡Œæ—¶é—´
                if current_time == schedule_time:
                    # æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»æ‰§è¡Œè¿‡è‚¡ç¥¨åˆ†æ
                    stock_last_run_file = os.path.join(self.log_dir, "last_run.txt")
                    
                    if os.path.exists(stock_last_run_file):
                        with open(stock_last_run_file, 'r') as f:
                            stock_last_run_date = f.read().strip()
                    else:
                        stock_last_run_date = ""
                    
                    if stock_last_run_date != today:
                        self.logger.info(f"åˆ°è¾¾é¢„å®šæ‰§è¡Œæ—¶é—´: {schedule_time}ï¼Œå¼€å§‹æ‰§è¡Œè‚¡ç¥¨åˆ†æ")
                        
                        # è¿è¡Œåˆ†æ
                        push_message = self.run_analysis()
                        
                        if push_message:
                            self.logger.info("å‡†å¤‡å‘é€è‚¡ç¥¨åˆ†æé€šçŸ¥")
                            # å‘é€é€šçŸ¥
                            self.send_notification(push_message)
                        else:
                            self.logger.error("æ— æ³•è·å–è‚¡ç¥¨åˆ†ææ¨é€æ¶ˆæ¯ï¼Œé€šçŸ¥å‘é€å¤±è´¥")
                        
                        # è®°å½•ä»Šå¤©å·²æ‰§è¡Œ
                        with open(stock_last_run_file, 'w') as f:
                            f.write(today)
                        
                        self.logger.info(f"ä»Šæ—¥è‚¡ç¥¨åˆ†æä»»åŠ¡å·²å®Œæˆï¼Œä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: æ˜å¤©{schedule_time}")
                    else:
                        self.logger.info(f"ä»Šå¤©({today})å·²ç»æ‰§è¡Œè¿‡è‚¡ç¥¨åˆ†æä»»åŠ¡ï¼Œè·³è¿‡æœ¬æ¬¡æ‰§è¡Œ")
                
                # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                time.sleep(60)
                
            except KeyboardInterrupt:
                self.logger.info("å®šæ—¶ä»»åŠ¡å·²è¢«ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                self.logger.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                # å‘ç”Ÿå¼‚å¸¸åï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´å†ç»§ç»­ï¼Œé¿å…é¢‘ç¹å‡ºé”™
                time.sleep(300)  # ç­‰å¾…5åˆ†é’Ÿ
    
    def update_config(self, new_config):
        """æ›´æ–°é…ç½®ï¼ˆä»…åœ¨å†…å­˜ä¸­æ›´æ–°ï¼Œä¸å†ä¿å­˜åˆ°æ–‡ä»¶ï¼‰"""
        try:
            # åˆå¹¶æ–°é…ç½®
            self.config.update(new_config)
            
            self.logger.info("é…ç½®å·²åœ¨å†…å­˜ä¸­æ›´æ–°")
            return True
        except Exception as e:
            self.logger.error(f"æ›´æ–°é…ç½®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return False

# ä¸»å‡½æ•°
def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºè‡ªåŠ¨åˆ†æå™¨å®ä¾‹
    auto_analyzer = AutoStockAnalyzer()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description='è‡ªåŠ¨è¿è¡Œè‚¡ç¥¨åˆ†æç¨‹åºå¹¶æ¨é€ç»“æœ')
    parser.add_argument('--once', action='store_true', help='ä»…è¿è¡Œä¸€æ¬¡å¹¶é€€å‡º')
    parser.add_argument('--schedule', action='store_true', help='å¯åŠ¨å®šæ—¶ä»»åŠ¡æ¨¡å¼')
    
    # åˆ†æç±»å‹å‚æ•°
    parser.add_argument('--industry', action='store_true', help='ä»…è¿è¡Œè¡Œä¸šèµ„é‡‘æµå‘åˆ†æ')
    parser.add_argument('--volume', action='store_true', help='ä»…è¿è¡Œä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡åˆ†æ')
    # ç§»é™¤--uså‚æ•°ï¼Œå› ä¸ºstock_analysis.pyä¸æ”¯æŒè¿™ä¸ªå‚æ•°
    parser.add_argument('--all', action='store_true', help='è¿è¡Œæ‰€æœ‰åˆ†æ')
    # æ·»åŠ è´¢ç»è¦é—»å‚æ•°
    parser.add_argument('--news', action='store_true', help='ä»…è¿è¡Œè´¢ç»è¦é—»è·å–å’Œæ¨é€åŠŸèƒ½')
    parser.add_argument('--newsapi', action='store_true', help='ä»…ä½¿ç”¨NewsAPIè·å–å’Œæ¨é€è´¢ç»è¦é—»')
    
    args = parser.parse_args()
    
    # æ ¹æ®å‚æ•°æ‰§è¡Œä¸åŒçš„é€»è¾‘
    if args.newsapi:
        # ä»…ä½¿ç”¨NewsAPIè¿è¡Œè´¢ç»è¦é—»åŠŸèƒ½ï¼Œå…ˆæ£€æŸ¥ç½‘ç»œè¿æ¥
        print("\n===== NewsAPIè´¢ç»è¦é—»åŠŸèƒ½ ======")
        print("æ­£åœ¨æ£€æŸ¥NewsAPIæœåŠ¡è¿æ¥çŠ¶æ€...")
        
        # æ£€æŸ¥ç½‘ç»œè¿æ¥
        try:
            import socket
            socket.setdefaulttimeout(5)
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.connect(('newsapi.org', 80))
            print("âœ“ NewsAPIæœåŠ¡è¿æ¥æµ‹è¯•é€šè¿‡")
        except Exception as e:
            print("\nâŒ NewsAPIæœåŠ¡è¿æ¥æµ‹è¯•å¤±è´¥")
            print("é”™è¯¯ä¿¡æ¯: æ— æ³•è¿æ¥åˆ°newsapi.orgæœåŠ¡å™¨")
            print("\nç½‘ç»œè¿æ¥è¯Šæ–­ç»“æœ:")
            print("- æ‚¨çš„ç½‘ç»œå¯èƒ½æ— æ³•è®¿é—®newsapi.org")
            print("- å¯èƒ½æ˜¯ç½‘ç»œé™åˆ¶æˆ–é˜²ç«å¢™é˜»æ­¢äº†è¿æ¥")
            print("- è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè®¾ç½®")
            print("\nå»ºè®®è§£å†³æ–¹æ¡ˆ:")
            print("1. å°è¯•ä½¿ç”¨ --news å‚æ•°ä»£æ›¿ --newsapi")
            print("2. ä½¿ç”¨ --news å‚æ•°å¯ä»¥å¯ç”¨å¤šçº§å›é€€æœºåˆ¶ (Kimiâ†’æœ¬åœ°â†’NewsAPIâ†’çˆ¬è™«)")
            print("3. æ£€æŸ¥æ‚¨çš„ç½‘ç»œè®¾ç½®å’Œé˜²ç«å¢™è§„åˆ™")
            print("\næ˜¯å¦ç»§ç»­å°è¯•ä½¿ç”¨NewsAPI? (y/n): ")
            
            # è·å–ç”¨æˆ·è¾“å…¥
            try:
                user_input = input().strip().lower()
                if user_input != 'y':
                    print("å·²å–æ¶ˆNewsAPIè´¢ç»è¦é—»åŠŸèƒ½")
                    return
            except:
                print("æ— æ³•è·å–ç”¨æˆ·è¾“å…¥ï¼Œç»§ç»­æ‰§è¡Œ...")
        
        auto_analyzer.logger.info("===== ä½¿ç”¨NewsAPIè¿è¡Œè´¢ç»è¦é—»è·å–åŠŸèƒ½ ======")
        today = datetime.now().strftime("%Y-%m-%d")
        auto_analyzer.logger.info(f"å¼€å§‹ä½¿ç”¨NewsAPIè·å–æœ€æ–°è´¢ç»è¦é—» ({today})")
        success = auto_analyzer.newsapi_news.send_news_notification()
        if success:
            auto_analyzer.logger.info("NewsAPIè´¢ç»è¦é—»æ¨é€å®Œæˆ")
        else:
            auto_analyzer.logger.error("NewsAPIè´¢ç»è¦é—»æ¨é€å¤±è´¥")
        auto_analyzer.logger.info("===== NewsAPIè´¢ç»è¦é—»è·å–åŠŸèƒ½æ‰§è¡Œå®Œæ¯• =====")
    elif args.news:
        # ä»…è¿è¡Œè´¢ç»è¦é—»åŠŸèƒ½
        auto_analyzer.run_news_only()
    elif args.once:
        # ä»…è¿è¡Œä¸€æ¬¡
        auto_analyzer.run_once()
    elif args.schedule:
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡æ¨¡å¼
        try:
            auto_analyzer.run_scheduled()
        except KeyboardInterrupt:
            print("\nå®šæ—¶ä»»åŠ¡å·²è¢«ç”¨æˆ·ä¸­æ–­")
    else:
        # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python auto_analyzer.py --once       # ä»…è¿è¡Œä¸€æ¬¡å¹¶é€€å‡º")
        print("  python auto_analyzer.py --schedule   # å¯åŠ¨å®šæ—¶ä»»åŠ¡æ¨¡å¼")
        print("\nåˆ†æç±»å‹é€‰é¡¹ï¼ˆå¯ä¸--onceä¸€èµ·ä½¿ç”¨ï¼‰:")
        print("  --industry   # ä»…è¿è¡Œè¡Œä¸šèµ„é‡‘æµå‘åˆ†æ")
        print("  --volume     # ä»…è¿è¡Œä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡åˆ†æ")
        # ç§»é™¤--uså‚æ•°è¯´æ˜ï¼Œå› ä¸ºstock_analysis.pyä¸æ”¯æŒè¿™ä¸ªå‚æ•°
        print("  --all        # è¿è¡Œæ‰€æœ‰åˆ†æ")
        print("  --news       # ä»…è¿è¡Œè´¢ç»è¦é—»è·å–å’Œæ¨é€åŠŸèƒ½ï¼ˆä½¿ç”¨é»˜è®¤çš„å¤šçº§å›é€€æœºåˆ¶ï¼‰")
        print("  --newsapi    # ä»…ä½¿ç”¨NewsAPIè·å–å’Œæ¨é€è´¢ç»è¦é—»")
        print("\nç¤ºä¾‹:")
        print("  python auto_analyzer.py --once --industry --volume  # è¿è¡Œè¡Œä¸šèµ„é‡‘å’Œæˆäº¤é‡åˆ†æ")
        print("  python auto_analyzer.py --news  # ä»…è¿è¡Œè´¢ç»è¦é—»è·å–å’Œæ¨é€åŠŸèƒ½")
        print("  python auto_analyzer.py --newsapi  # ä»…ä½¿ç”¨NewsAPIè·å–å’Œæ¨é€è´¢ç»è¦é—»")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå‚æ•°ï¼Œé»˜è®¤ä»…è¿è¡Œä¸€æ¬¡
        print("\næœªæŒ‡å®šå‚æ•°ï¼Œé»˜è®¤ä»…è¿è¡Œä¸€æ¬¡åˆ†æ")
        auto_analyzer.run_once()

if __name__ == "__main__":
    main()