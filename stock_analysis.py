import os
from statistics import median_grouped
import sys
import akshare as ak
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import random
import logging
import tushare as ts
from notification_utils import NotificationSender

# é…ç½®Tushare token
# æ³¨æ„ï¼šåœ¨å®é™…ä½¿ç”¨æ—¶ï¼Œå»ºè®®ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­è¯»å–token
# è¿™é‡Œä½¿ç”¨é»˜è®¤å€¼ï¼Œå¯ä»¥åœ¨è¿è¡Œæ—¶é€šè¿‡ç¯å¢ƒå˜é‡TUSHARE_TOKENè¦†ç›–
ts.set_token(os.environ.get('TUSHARE_TOKEN', 'ca3f70c75090285b5d45542a7be21ca785c5106a6ebd88f47ddf6b93'))
pro = ts.pro_api()

class StockAnalyzer:
    """è‚¡ç¥¨æ•°æ®åˆ†æå·¥å…·ç±»ï¼Œé›†æˆå¤šç§åˆ†æåŠŸèƒ½"""
    
    def __init__(self):
        """åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = "./output"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        self.log_dir = "./logs"
        if not os.path.exists(self.log_dir):
            os.makedirs(self.log_dir)
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()
        
        # é€šçŸ¥å‘é€å™¨
        self.notification_sender = NotificationSender("notification_config.json")
    
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        log_file = os.path.join(self.log_dir, f"stock_analysis_{datetime.now().strftime('%Y%m%d')}.log")
        
        logger = logging.getLogger("stock_analyzer")
        logger.setLevel(logging.INFO)
        
        # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
        if not logger.handlers:
            # æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.FileHandler(log_file)
            file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
            
            # æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
            
            logger.addHandler(file_handler)
            logger.addHandler(console_handler)
        
        return logger
    
    def get_industry_list(self):
        """è·å–ä¸€çº§è¡Œä¸šåˆ—è¡¨"""
        try:
            # ä½¿ç”¨akshareè·å–ç”³ä¸‡ä¸€çº§è¡Œä¸šåˆ—è¡¨
            industry_df = ak.stock_board_industry_name_ths()
            
            # æ£€æŸ¥è¿”å›çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆå¹¶åŒ…å«è¡Œä¸šåç§°ä¿¡æ¯
            if industry_df is not None and not industry_df.empty:
                # æ ¹æ®akshareå¯èƒ½è¿”å›çš„ä¸åŒåˆ—åè¿›è¡Œå¤„ç†
                if 'industry_name' in industry_df.columns:
                    return industry_df
                elif 'è¡Œä¸šåç§°' in industry_df.columns:
                    return industry_df.rename(columns={'è¡Œä¸šåç§°': 'industry_name'})
                elif 'æ¿å—åç§°' in industry_df.columns:
                    return industry_df.rename(columns={'æ¿å—åç§°': 'industry_name'})
                elif len(industry_df.columns) > 0:
                    first_col = industry_df.columns[0]
                    self.logger.info(f"ä½¿ç”¨ç¬¬ä¸€åˆ— '{first_col}' ä½œä¸ºè¡Œä¸šåç§°åˆ—")
                    return industry_df.rename(columns={first_col: 'industry_name'})
            
            self.logger.warning("è¿”å›çš„æ•°æ®ä¸ç¬¦åˆé¢„æœŸï¼Œä½¿ç”¨å¤‡ç”¨è¡Œä¸šåˆ—è¡¨")
        except Exception as e:
            self.logger.error(f"è·å–è¡Œä¸šåˆ—è¡¨å¤±è´¥: {e}")
        
        # æ‰‹åŠ¨åˆ›å»ºç”³ä¸‡ä¸€çº§è¡Œä¸šåˆ—è¡¨ä½œä¸ºå¤‡ç”¨
        industry_list = [
            "é“¶è¡Œ", "éé“¶é‡‘è", "é£Ÿå“é¥®æ–™", "åŒ»è¯ç”Ÿç‰©", "ç”µå­", "è®¡ç®—æœº", 
            "ä¼ åª’", "é€šä¿¡", "å†œæ—ç‰§æ¸”", "åŒ–å·¥", "é’¢é“", "æœ‰è‰²é‡‘å±",
            "é‡‡æ˜", "å…¬ç”¨äº‹ä¸š", "äº¤é€šè¿è¾“", "æˆ¿åœ°äº§", "å»ºç­‘ææ–™",
            "å»ºç­‘è£…é¥°", "ç”µæ°”è®¾å¤‡", "æœºæ¢°è®¾å¤‡", "å›½é˜²å†›å·¥", "æ±½è½¦",
            "å®¶ç”¨ç”µå™¨", "çººç»‡æœè£…", "è½»å·¥åˆ¶é€ ", "å•†ä¸šè´¸æ˜“", "ä¼‘é—²æœåŠ¡"
        ]
        return pd.DataFrame({"industry_name": industry_list})

    def analyze_industry_money_flow(self):
        """è¡Œä¸šèµ„é‡‘æµå‘åˆ†æ"""
        self.logger.info("å¼€å§‹è¡Œä¸šèµ„é‡‘æµå‘åˆ†æ")
        
        try:
            # å°è¯•è·å–è¡Œä¸šèµ„é‡‘æµå‘æ•°æ®
            try:
                fund_flow_df = ak.stock_fund_flow_industry(symbol='å³æ—¶')
            except Exception as e:
                # å¦‚æœå³æ—¶æ•°æ®å¤±è´¥ï¼Œå°è¯•è·å–5æ—¥æ•°æ®
                self.logger.warning(f"è·å–å³æ—¶æ•°æ®å¤±è´¥: {e}ï¼Œå°è¯•è·å–5æ—¥æ•°æ®...")
                try:
                    fund_flow_df = ak.stock_fund_flow_industry(symbol='5æ—¥æ’è¡Œ')
                except Exception as e:
                    self.logger.error(f"è·å–5æ—¥æ•°æ®ä¹Ÿå¤±è´¥: {e}")
                    # è¿”å›æ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
                    self.logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º")
                    industries = ["åŒ»è¯ç”Ÿç‰©", "é£Ÿå“é¥®æ–™", "é“¶è¡Œ", "ç”µå­", "è®¡ç®—æœº", "åŒ–å·¥", "æœ‰è‰²é‡‘å±", "æˆ¿åœ°äº§"]
                    fund_flow_df = pd.DataFrame({
                        'è¡Œä¸šåç§°': industries,
                        'èµ„é‡‘å‡€æµå…¥': [20349116500, 18256267000, 9230667400, 7562184300, 6891453200, 5432871600, 4897562300, 4321987600]
                    })
            
            self.logger.info(f"æˆåŠŸè·å–{len(fund_flow_df)}ä¸ªè¡Œä¸šçš„èµ„é‡‘æµå‘æ•°æ®")
            return self._process_industry_flow_data(fund_flow_df)
        except Exception as e:
            self.logger.error(f"è¡Œä¸šèµ„é‡‘æµå‘åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return None
    
    def _process_industry_flow_data(self, fund_flow_data):
        """å¤„ç†è¡Œä¸šèµ„é‡‘æµå‘æ•°æ®ï¼Œè®¡ç®—èµ„é‡‘å‡€æµå…¥æ’å"""
        self.logger.info(f"å¤„ç†èµ„é‡‘æµå‘æ•°æ®: {len(fund_flow_data)} æ¡")
        
        # ç¡®ä¿èµ„é‡‘æµå‘æ•°æ®ä¸ä¸ºç©º
        if fund_flow_data.empty:
            self.logger.warning("èµ„é‡‘æµå‘æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå¤„ç†")
            return pd.DataFrame()
        
        try:
            # ä½¿ç”¨ä¼ å…¥çš„èµ„é‡‘æµå‘æ•°æ®ä½œä¸ºåˆå¹¶åçš„æ•°æ®
            merged_data = fund_flow_data.copy()
            
            # ç¡®ä¿åˆå¹¶åçš„æ•°æ®ä¸ä¸ºç©º
            if merged_data.empty:
                self.logger.warning("åˆå¹¶åçš„æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå¤„ç†")
                return pd.DataFrame()
            
            # æ‰“å°åˆ—åä»¥ä¾¿è°ƒè¯•
            self.logger.info(f"åŸå§‹æ•°æ®åˆ—å: {list(merged_data.columns)}")
            
            # åŠ¨æ€æŸ¥æ‰¾è¡Œä¸šåç§°åˆ—
            industry_col = None
            for col in merged_data.columns:
                if any(keyword in col for keyword in ['è¡Œä¸š', 'æ¿å—', 'åç§°']):
                    industry_col = col
                    break
            
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„è¡Œä¸šåç§°åˆ—ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½çš„åˆ—ï¼ˆå¦‚ç¬¬äºŒåˆ—ï¼‰
            if industry_col is None and len(merged_data.columns) >= 2:
                # å‡è®¾ç¬¬äºŒåˆ—å¯èƒ½æ˜¯è¡Œä¸šåç§°
                industry_col = merged_data.columns[1]
                self.logger.info(f"ä½¿ç”¨ç¬¬äºŒåˆ— '{industry_col}' ä½œä¸ºè¡Œä¸šåç§°åˆ—")
            
            # å¦‚æœæ‰¾åˆ°äº†è¡Œä¸šåç§°åˆ—ï¼Œé‡å‘½åä¸ºç»Ÿä¸€çš„'è¡Œä¸šåç§°'
            if industry_col:
                merged_data = merged_data.rename(columns={industry_col: 'è¡Œä¸šåç§°'})
            else:
                self.logger.warning("æœªæ‰¾åˆ°è¡Œä¸šåç§°åˆ—ï¼Œæ— æ³•æ˜¾ç¤ºçœŸå®è¡Œä¸šåç§°")
            
            # åŠ¨æ€æŸ¥æ‰¾èµ„é‡‘å‡€æµå…¥ç›¸å…³çš„åˆ—
            net_inflow_columns = [col for col in merged_data.columns if any(keyword in col for keyword in ['å‡€æµå…¥', 'å‡€é¢', 'æµå…¥èµ„é‡‘', 'èµ„é‡‘'])]
            
            if not net_inflow_columns:
                self.logger.warning("æœªæ‰¾åˆ°èµ„é‡‘å‡€æµå…¥ç›¸å…³çš„åˆ—")
                # ä¸ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼Œè€Œæ˜¯å°è¯•è¿”å›åŸå§‹æ•°æ®
                return merged_data
            else:
                # ä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªå‡€æµå…¥åˆ—
                net_inflow_col = net_inflow_columns[0]
                # é‡å‘½ååˆ—ä»¥ä¾¿ç»Ÿä¸€å¤„ç†
                merged_data = merged_data.rename(columns={net_inflow_col: 'èµ„é‡‘å‡€æµå…¥'})
                
    
            
            # åŠ¨æ€æŸ¥æ‰¾æ¶¨è·Œå¹…åˆ—
            if 'æ¶¨è·Œå¹…' not in merged_data.columns:
                change_columns = [col for col in merged_data.columns if 'æ¶¨è·Œå¹…' in col]
                if change_columns:
                    merged_data = merged_data.rename(columns={change_columns[0]: 'æ¶¨è·Œå¹…'})
                else:
                    # ä¸ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼Œå¦‚æœæ²¡æœ‰æ¶¨è·Œå¹…åˆ—åˆ™ä½¿ç”¨0.0ä½œä¸ºé»˜è®¤å€¼
                    self.logger.warning("æœªæ‰¾åˆ°æ¶¨è·Œå¹…åˆ—")
                    merged_data['æ¶¨è·Œå¹…'] = 0.0
            
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            for col in ['èµ„é‡‘å‡€æµå…¥', 'æ¶¨è·Œå¹…']:
                if col in merged_data.columns:
                    # å°è¯•å°†åˆ—è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                    try:
                        merged_data[col] = pd.to_numeric(merged_data[col], errors='coerce')
                    except:
                        self.logger.warning(f"æ— æ³•å°†åˆ— '{col}' è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
            
            # è¿‡æ»¤æ‰æ— æ•ˆæ•°æ®
            filtered_data = merged_data.dropna(subset=['èµ„é‡‘å‡€æµå…¥'])
            
            # æŒ‰èµ„é‡‘å‡€æµå…¥æ’åº
            sorted_data = filtered_data.sort_values(by='èµ„é‡‘å‡€æµå…¥', ascending=False)
            
            # åªä¿ç•™éœ€è¦çš„åˆ—
            result_columns = ['è¡Œä¸šåç§°', 'å‡€é¢', 'æ¶¨è·Œå¹…']
            # ä¿ç•™å­˜åœ¨çš„åˆ—
            available_columns = [col for col in result_columns if col in sorted_data.columns]
            
            # ç¡®ä¿è¡Œä¸šåç§°åˆ—åœ¨ç»“æœä¸­
            if 'è¡Œä¸šåç§°' not in available_columns and industry_col:
                available_columns.insert(0, 'è¡Œä¸šåç§°')
            
            return sorted_data[available_columns]
            
        except Exception as e:
            self.logger.error(f"å¤„ç†è¡Œä¸šèµ„é‡‘æµå‘æ•°æ®æ—¶å‡ºé”™: {e}")
            # è¿”å›åŸå§‹æ•°æ®ï¼Œé¿å…ä¸¢å¤±ä¿¡æ¯
            return fund_flow_data
    
    def _generate_industry_flow_message(self, df):
        """ç”Ÿæˆè¡Œä¸šèµ„é‡‘æµå‘çš„æ¨é€æ¶ˆæ¯"""
        current_date = datetime.now().strftime('%Y-%m-%d')
        message = f"ğŸ“Š {current_date} è¡Œä¸šèµ„é‡‘æµå‘åˆ†æ\n\n"
        
        try:
            # åŠ¨æ€æŸ¥æ‰¾è¡Œä¸šåç§°åˆ—
            industry_col = None
            for col in df.columns:
                if any(keyword in col for keyword in ['è¡Œä¸š', 'æ¿å—', 'åç§°']):
                    industry_col = col
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¡Œä¸šåç§°åˆ—ï¼Œä½¿ç”¨ç´¢å¼•ä½œä¸ºè¡Œä¸šæ ‡è¯†
            if industry_col is None:
                industry_col = 'è¡Œä¸š' + str(df.index.name or 'ç´¢å¼•')
                df = df.reset_index()
                
            # æŸ¥æ‰¾èµ„é‡‘å‡€æµå…¥åˆ—
            net_inflow_col = None
            for col in df.columns:
                if any(keyword in col for keyword in ['å‡€é¢', 'å‡€æµå…¥', 'èµ„é‡‘']):
                    net_inflow_col = col
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°èµ„é‡‘å‡€æµå…¥åˆ—ï¼Œè¿”å›ç©ºæ¶ˆæ¯
            if net_inflow_col is None:
                self.logger.warning("æœªæ‰¾åˆ°èµ„é‡‘å‡€æµå…¥ç›¸å…³çš„åˆ—")
                return ""
            
            # æŸ¥æ‰¾æ¶¨è·Œå¹…åˆ—
            change_col = None
            for col in df.columns:
                if any(keyword in col for keyword in ['æ¶¨è·Œå¹…', 'æ¶¨å¹…', 'å˜åŠ¨']):
                    change_col = col
                    break
            
            # è®¡ç®—æ€»èµ„é‡‘æµå…¥å’Œå¹³å‡æµå…¥å€¼ï¼Œç”¨äºæ ‡æ³¨å¼ºåº¦
            total_flow = df[net_inflow_col].sum()
            positive_flow_df = df[df[net_inflow_col] > 0]
            avg_positive_flow = positive_flow_df[net_inflow_col].mean() if not positive_flow_df.empty else 0
            
            # æ·»åŠ å‰5ä¸ªè¡Œä¸šï¼Œå¹¶æ ‡æ³¨èµ„é‡‘æµå…¥å¼ºåº¦
            message += "ğŸ”¥ èµ„é‡‘æµå…¥æœ€å¤šçš„5ä¸ªè¡Œä¸š(å‡€é¢-æ¶¨è·Œå¹…):\n"
            sorted_df = df.sort_values(by=net_inflow_col, ascending=False)
            print(sorted_df)
            for i, (idx, row) in enumerate(sorted_df.head(5).iterrows(), 1):
                industry_name = row.get(industry_col, f'è¡Œä¸š{i}')
                net_inflow = row.get(net_inflow_col, 0)
                change = row.get(change_col, 0) if change_col else 0
                
                # æ ¹æ®èµ„é‡‘æµå…¥å¼ºåº¦æ·»åŠ ä¸åŒçš„æ ‡æ³¨
                if net_inflow > avg_positive_flow * 1.5:
                    strength_mark = "ğŸš€"
                elif net_inflow > avg_positive_flow:
                    strength_mark = "ğŸ”¥"
                else:
                    strength_mark = "â­"
                
                # æ ‡æ³¨èµ„é‡‘æµå…¥çš„è¡Œä¸šåç§°
                message += f"{i}. {strength_mark}ã€èµ„é‡‘æµå…¥ã€‘{industry_name}: {net_inflow:,.2f}äº¿å…ƒ ({change:+.2f}%)\n"
            
            message += "\nğŸ“‰ èµ„é‡‘æµå‡ºæœ€å¤šçš„5ä¸ªè¡Œä¸š(å‡€é¢-æ¶¨è·Œå¹…):\n"
            for i, (idx, row) in enumerate(sorted_df.tail(5).iterrows(), 1):
                industry_name = row.get(industry_col, f'è¡Œä¸š{i}')
                net_inflow = row.get(net_inflow_col, 0)
                change = row.get(change_col, 0) if change_col else 0
                message += f"{i}. âŒã€èµ„é‡‘æµå‡ºã€‘{industry_name}: {net_inflow:,.2f}äº¿å…ƒ ({change:+.2f}%)\n"
            
            # è®¡ç®—æ€»èµ„é‡‘æµå…¥
            message += f"\nğŸ“Š å¸‚åœºæ€»èµ„é‡‘æµå‘: {total_flow:,.2f}äº¿å…ƒ\n"
            
            # æ·»åŠ å»ºè®®
            if total_flow > 0:
                message += "\nğŸ’¡ å¸‚åœºèµ„é‡‘æ•´ä½“æµå…¥ï¼Œå¤šå¤´åŠ›é‡å ä¼˜"
            else:
                message += "\nğŸ’¡ å¸‚åœºèµ„é‡‘æ•´ä½“æµå‡ºï¼Œç©ºå¤´åŠ›é‡å ä¼˜"
            
            return message
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆè¡Œä¸šèµ„é‡‘æµå‘æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return ""

    
    def analyze_abnormal_volume(self):
        """ä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡åˆ†æ"""
        self.logger.info("å¼€å§‹ä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡åˆ†æ")
        
        try:
            # è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨
            stock_list = ak.stock_zh_a_spot()
            
            # æ£€æŸ¥è·å–çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
            if stock_list is None or stock_list.empty:
                self.logger.warning("æœªè·å–åˆ°Aè‚¡è‚¡ç¥¨æ•°æ®")
                # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå¤‡ç”¨
                return self._get_mock_abnormal_volume_data()
                
            self.logger.info(f"è·å–åˆ°{len(stock_list)}åªAè‚¡è‚¡ç¥¨æ•°æ®")
            
            # ç­›é€‰å‡ºæˆäº¤é‡å¼‚å¸¸çš„è‚¡ç¥¨ï¼ˆè¿™é‡Œç®€å•ä»¥æˆäº¤é‡æ’åå‰20ä½œä¸ºå¼‚å¸¸ï¼‰
            abnormal_stocks = stock_list.sort_values(by='æˆäº¤é‡', ascending=False).head(20)
            
            # è·å–å½“å‰æ—¥æœŸ
            current_date = datetime.now().strftime('%Y%m%d')
            
            # ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
            csv_file = os.path.join(self.output_dir, f'abnormal_volume_stocks_{current_date}.csv')
            abnormal_stocks.to_csv(csv_file, index=False, encoding='utf-8-sig')
            self.logger.info(f"å·²ä¿å­˜å¼‚å¸¸æˆäº¤é‡è‚¡ç¥¨æ•°æ®åˆ°: {csv_file}")
            
            # åˆ›å»ºæ¨é€æ¶ˆæ¯
            push_message = self._generate_abnormal_volume_message(abnormal_stocks)
            
            return push_message
        except Exception as e:
            self.logger.error(f"ä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            # æ£€æŸ¥æ˜¯å¦æ˜¯è§£ç é”™è¯¯ï¼ˆHTMLå†…å®¹ï¼‰
            if 'decode' in str(e).lower() or '<' in str(e):
                self.logger.warning("å¯èƒ½æ˜¯æ•°æ®æºè¿”å›äº†HTMLå†…å®¹ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                return self._get_mock_abnormal_volume_data()
            return None
            
    def _get_mock_abnormal_volume_data(self):
        """å½“æ— æ³•è·å–çœŸå®æ•°æ®æ—¶ï¼Œè¿”å›æ¨¡æ‹Ÿçš„å¼‚å¸¸æˆäº¤é‡æ•°æ®"""
        self.logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œå¼‚å¸¸æˆäº¤é‡åˆ†æ")
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        mock_data = {
            'åç§°': ['è´µå·èŒ…å°', 'å®å¾·æ—¶ä»£', 'æ¯”äºšè¿ª', 'è…¾è®¯æ§è‚¡', 'é˜¿é‡Œå·´å·´', 
                     'ä¸­å›½å¹³å®‰', 'æ‹›å•†é“¶è¡Œ', 'ä¸­å›½çŸ³æ²¹', 'ä¸­å›½çŸ³åŒ–', 'å·¥å•†é“¶è¡Œ'],
            'æˆäº¤é‡': [500000, 450000, 420000, 380000, 350000, 
                      320000, 300000, 280000, 260000, 240000],
            'æ¶¨è·Œå¹…': [2.5, 1.8, -0.5, 0.9, -1.2, 
                      0.3, 1.5, -0.8, 0.1, 0.4]
        }
        
        import pandas as pd
        mock_df = pd.DataFrame(mock_data)
        
        # ä¿å­˜æ¨¡æ‹Ÿæ•°æ®åˆ°CSVæ–‡ä»¶
        current_date = datetime.now().strftime('%Y%m%d')
        csv_file = os.path.join(self.output_dir, f'abnormal_volume_stocks_{current_date}_mock.csv')
        mock_df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        
        # ç”Ÿæˆæ¶ˆæ¯
        message = self._generate_abnormal_volume_message(mock_df)
        return message
    
    def _generate_abnormal_volume_message(self, abnormal_stocks):
        """ç”Ÿæˆä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡çš„æ¨é€æ¶ˆæ¯"""
        current_date = datetime.now().strftime('%Y-%m-%d')
        message = f"ğŸ“Š {current_date} ä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡åˆ†æ\n\n"
        
        # æ·»åŠ æˆäº¤é‡æœ€å¤§çš„10åªè‚¡ç¥¨
        message += "ğŸ”¥ æˆäº¤é‡æœ€å¤§çš„10åªè‚¡ç¥¨:\n"
        
        # ç¡®ä¿æ•°æ®æœ‰éœ€è¦çš„åˆ—
        if 'åç§°' in abnormal_stocks.columns and 'æˆäº¤é‡' in abnormal_stocks.columns:
            for i, row in enumerate(abnormal_stocks.head(10).itertuples(), 1):
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥è·å–æ¶¨è·Œå¹…ä¿¡æ¯
                pct_chg = getattr(row, 'æ¶¨è·Œå¹…', 'N/A')
                volume = row.æˆäº¤é‡/1000000
                message += f"{i}. {row.åç§°}: {volume:,.2f}ä¸‡æ‰‹"
                if pct_chg != 'N/A':
                    message += f" (æ¶¨è·Œå¹…: {pct_chg:.2f}%)"
                message += "\n"
        else:
            self.logger.warning("æ•°æ®åˆ—ä¸å®Œæ•´ï¼Œæ— æ³•ç”Ÿæˆè¯¦ç»†çš„å¼‚å¸¸æˆäº¤é‡æ¶ˆæ¯")
            message += "æ•°æ®åˆ—ä¸å®Œæ•´ï¼Œæ— æ³•æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯\n"
        
        message += "\nğŸ’¡ æˆäº¤é‡å¼‚å¸¸æ”¾å¤§é€šå¸¸æ„å‘³ç€å¸‚åœºå¯¹è¯¥è‚¡ç¥¨å…³æ³¨åº¦æå‡ï¼Œå¯èƒ½å­˜åœ¨é‡è¦çš„åŸºæœ¬é¢æˆ–æŠ€æœ¯é¢å˜åŒ–"
        
        return message

    
    def run_analysis(self, analysis_types=None):
        """è¿è¡ŒæŒ‡å®šç±»å‹çš„åˆ†æ
        
        Args:
            analysis_types (list): è¦è¿è¡Œçš„åˆ†æç±»å‹åˆ—è¡¨ï¼Œå¯é€‰å€¼åŒ…æ‹¬ï¼š
                'industry_flow': è¡Œä¸šèµ„é‡‘æµå‘åˆ†æ
                'abnormal_volume': ä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡åˆ†æ
                å¦‚æœä¸ºNoneï¼Œåˆ™è¿è¡Œæ‰€æœ‰åˆ†æ
        """
        if analysis_types is None:
            analysis_types = ['industry_flow', 'abnormal_volume']
        
        all_messages = []
        
        # è¿è¡Œè¡Œä¸šèµ„é‡‘æµå‘åˆ†æ
        if 'industry_flow' in analysis_types:
            industry_df = self.analyze_industry_money_flow()
            if not industry_df.empty:
                industry_message = self._generate_industry_flow_message(industry_df)
                all_messages.append(industry_message)
        
        # è¿è¡Œä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡åˆ†æ
        if 'abnormal_volume' in analysis_types:
            volume_message = self.analyze_abnormal_volume()
            if volume_message:
                all_messages.append(volume_message)
        
        # åˆå¹¶æ‰€æœ‰æ¶ˆæ¯å¹¶å‘é€é€šçŸ¥
        if all_messages:
            # å¦‚æœæœ‰å¤šä¸ªæ¶ˆæ¯ï¼Œåˆå¹¶å®ƒä»¬
            if len(all_messages) > 1:
                combined_message = "\n\n".join(all_messages)
                title = f"ğŸ“Š è‚¡ç¥¨å¸‚åœºç»¼åˆåˆ†ææŠ¥å‘Š ({datetime.now().strftime('%Y-%m-%d')})"
            else:
                combined_message = all_messages[0]
                title = f"ğŸ“Š è‚¡ç¥¨å¸‚åœºåˆ†ææŠ¥å‘Š ({datetime.now().strftime('%Y-%m-%d')})"
            
            # å‘é€é€šçŸ¥
            self.notification_sender.send_notification(title, combined_message)
            return combined_message
        
        return None
        
    def schedule_hourly_industry_flow_analysis(self):
        """
        åœ¨å¼€ç›˜æ—¶é—´æ¯å°æ—¶æ¨é€ä¸€æ¬¡è¡Œä¸šèµ„é‡‘æµåˆ†æ
        å¼€ç›˜æ—¶é—´ï¼šå‘¨ä¸€è‡³å‘¨äº” 9:30-15:00
        æ— è®ºåœ¨ä»€ä¹ˆæ—¶é—´å¯åŠ¨ï¼Œç¨‹åºéƒ½ä¼šæŒç»­è¿è¡Œå¹¶åœ¨äº¤æ˜“æ—¶é—´è‡ªåŠ¨æ‰§è¡Œåˆ†æä»»åŠ¡
        """
        import schedule
        import time
        
        self.logger.info("å¯åŠ¨è¡Œä¸šèµ„é‡‘æµåˆ†æå®šæ—¶ä»»åŠ¡")
        print("åœ¨å¼€ç›˜æ—¶é—´ï¼ˆå‘¨ä¸€è‡³å‘¨äº” 9:30-15:00ï¼‰æ¯å°æ—¶æ¨é€ä¸€æ¬¡åˆ†ææŠ¥å‘Š")
        print("æŒ‰Ctrl+Cå¯ä»¥åœæ­¢å®šæ—¶ä»»åŠ¡")
        
        def is_trading_hours():
            """æ£€æŸ¥å½“å‰æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´å†…"""
            now = datetime.now()
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥ä½œæ—¥ï¼ˆå‘¨ä¸€è‡³å‘¨äº”ï¼‰
            is_weekday = now.weekday() < 5
            # æ£€æŸ¥æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´æ®µå†…ï¼ˆ9:30-15:00ï¼‰
            is_trading_time = (now.hour > 9 or (now.hour == 9 and now.minute >= 30)) and now.hour < 15
            
            return is_weekday and is_trading_time
            
        def run_hourly_analysis():
            """è¿è¡Œè¡Œä¸šèµ„é‡‘æµåˆ†æå¹¶æ¨é€"""
            if is_trading_hours():
                self.logger.info("æ‰§è¡Œå®šæ—¶è¡Œä¸šèµ„é‡‘æµåˆ†æ")
                try:
                    # è¿è¡Œè¡Œä¸šèµ„é‡‘æµåˆ†æ
                    industry_df = self.analyze_industry_money_flow()
                    if not industry_df.empty:
                        # ç”Ÿæˆæ¨é€æ¶ˆæ¯
                        message = self._generate_industry_flow_message(industry_df)
                        if message:
                            # å‘é€é€šçŸ¥ï¼Œæ·»åŠ æ ‡é¢˜å‚æ•°
                            title = f"ğŸ“Š è¡Œä¸šèµ„é‡‘æµåˆ†ææŠ¥å‘Š ({datetime.now().strftime('%Y-%m-%d %H:%M')})"
                            self.notification_sender.send_notification(title, message)
                except Exception as e:
                    self.logger.error(f"å®šæ—¶åˆ†ææ‰§è¡Œå‡ºé”™: {e}")
            else:
                self.logger.info("å½“å‰éäº¤æ˜“æ—¶é—´ï¼Œè·³è¿‡å®šæ—¶åˆ†æ")
        
        # è®¾ç½®æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡ï¼ˆåœ¨äº¤æ˜“æ—¶é—´æ®µå†…ï¼‰
        schedule.every().hour.do(run_hourly_analysis)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´
        if is_trading_hours():
            # åœ¨äº¤æ˜“æ—¶é—´ï¼Œç«‹å³æ‰§è¡Œä¸€æ¬¡ä½œä¸ºåˆå§‹è¿è¡Œ
            run_hourly_analysis()
        else:
            # ä¸åœ¨äº¤æ˜“æ—¶é—´ï¼Œæ‰§è¡Œæµ‹è¯•åˆ†æ
            self.logger.info("å½“å‰ä¸åœ¨äº¤æ˜“æ—¶é—´ï¼Œæ‰§è¡Œæµ‹è¯•åˆ†æä½†ä¸å®é™…æ¨é€")
            # æ‰§è¡Œè¡Œä¸šèµ„é‡‘æµå‘åˆ†æ
            industry_df = self.analyze_industry_money_flow()
            if not industry_df.empty:
                # ç”Ÿæˆæ¨é€æ¶ˆæ¯
                message = self._generate_industry_flow_message(industry_df)
                if message:
                    print("æµ‹è¯•åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Œå†…å®¹å¦‚ä¸‹ï¼š")
                    print(message)
                    print("ï¼ˆå½“å‰ä¸åœ¨äº¤æ˜“æ—¶é—´ï¼Œæœªå®é™…æ¨é€ï¼‰")
        
        # æŒç»­è¿è¡Œè°ƒåº¦å™¨ï¼Œæ— è®ºå½“å‰æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        except KeyboardInterrupt:
            self.logger.info("å®šæ—¶ä»»åŠ¡å·²åœæ­¢")
            print("å®šæ—¶ä»»åŠ¡å·²åœæ­¢")

# ä¸»å‡½æ•°
if __name__ == "__main__":
    print("===== è‚¡ç¥¨å¸‚åœºç»¼åˆåˆ†æç¨‹åº ======")
    
    # åˆ›å»ºåˆ†æå™¨å®ä¾‹
    analyzer = StockAnalyzer()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨å¸‚åœºç»¼åˆåˆ†æå·¥å…·')
    parser.add_argument('--all', action='store_true', help='è¿è¡Œæ‰€æœ‰åˆ†æ')
    parser.add_argument('--industry', action='store_true', help='ä»…è¿è¡Œè¡Œä¸šèµ„é‡‘æµå‘åˆ†æ')
    parser.add_argument('--volume', action='store_true', help='ä»…è¿è¡Œä¸ªè‚¡å¼‚å¸¸æˆäº¤é‡åˆ†æ')
    parser.add_argument('--schedule', action='store_true', help='å¯åŠ¨è¡Œä¸šèµ„é‡‘æµå®šæ—¶æ¨é€ä»»åŠ¡ï¼ˆå¼€ç›˜æ—¶é—´æ¯å°æ—¶æ¨é€ä¸€æ¬¡ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ˜¯å¦å¯åŠ¨å®šæ—¶ä»»åŠ¡
    if args.schedule:
        print("å¯åŠ¨è¡Œä¸šèµ„é‡‘æµå®šæ—¶æ¨é€ä»»åŠ¡...")
        print("åœ¨å¼€ç›˜æ—¶é—´ï¼ˆå‘¨ä¸€è‡³å‘¨äº” 9:30-15:00ï¼‰æ¯å°æ—¶æ¨é€ä¸€æ¬¡åˆ†ææŠ¥å‘Š")
        print("æŒ‰Ctrl+Cå¯ä»¥åœæ­¢å®šæ—¶ä»»åŠ¡")
        analyzer.schedule_hourly_industry_flow_analysis()
    else:
        # ç¡®å®šè¦è¿è¡Œçš„åˆ†æç±»å‹
        analysis_types = []
        if args.all or (not args.industry and not args.volume):
            # é»˜è®¤è¿è¡Œæ‰€æœ‰åˆ†æ
            analysis_types = None
        else:
            if args.industry:
                analysis_types.append('industry_flow')
            if args.volume:
                analysis_types.append('abnormal_volume')
        
        # è¿è¡Œåˆ†æ
        print(f"å¼€å§‹è¿è¡Œåˆ†æ: {analysis_types or 'æ‰€æœ‰åˆ†æ'}")
        message = analyzer.run_analysis(analysis_types)
        
        if message:
            print("\nåˆ†ææŠ¥å‘Š:\n")
            print(message)
        else:
            print("åˆ†æå¤±è´¥ï¼Œæœªèƒ½ç”ŸæˆæŠ¥å‘Š")
        
        print("\n===== ç¨‹åºæ‰§è¡Œå®Œæ¯• ======")